{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to sample the json files that serve as base for the hackaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from random import choice\n",
    "from datetime import timedelta, date\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_subsequences_of_random_length(l, n, m, p):\n",
    "    \"\"\" Takes the list l and generates subsequences of random length \n",
    "    \n",
    "    Each subsequence containd an element from l. \n",
    "    \n",
    "    The length of the subsequence is Binomial(m, p) distributed.\n",
    "    \n",
    "    Args:\n",
    "        l (list): the list with the elements of the subsequence\n",
    "        n (int): the size of the subsequence\n",
    "        m (int): the maximal size of subsequence (Binomial(m, p) distributed)\n",
    "        p (float): probability of the length of subsequence (Binomial(m, p) distributed)\n",
    "    \n",
    "    Will return the concatenated subsequences as list of size l.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    while len(result) < n:\n",
    "        result += [choice(l)] * int(np.random.binomial(m, p, 1))\n",
    "                   \n",
    "    return result[:n]\n",
    "\n",
    "\n",
    "# exemplary usage \n",
    "r = generate_subsequences_of_random_length(\"abcde\", 30, 5, 0.5)\n",
    "np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_data_frame_as_json(df, name):\n",
    "    \"\"\"Dumps a dataframe as json under name n,\n",
    "\n",
    "    make sure every row has its own line in the result file\n",
    "    \"\"\"\n",
    "    with open(name + \"_ temp\", 'w') as outfile:\n",
    "        json.dump(df.to_dict(orient='record'), outfile)\n",
    "    \n",
    "    with open(name + \"_ temp\", 'r') as outfile: \n",
    "        f = outfile.read().replace(\"},\", \"},\\n\")\n",
    "\n",
    "    with open(name, 'w') as outfile: \n",
    "        outfile.write(f)\n",
    "\n",
    "    os.remove(name + \"_ temp\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prod schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_total = 100\n",
    "n_seq = 8\n",
    "\n",
    "grade = generate_subsequences_of_random_length([\"STI1\", \"ST2\", \"PPQ\"], n_total, 10, 0.6)\n",
    "cu_range = generate_subsequences_of_random_length([0.08, 0.10, 0.12], n_total, 5, 0.3)\n",
    "al_range = generate_subsequences_of_random_length([0.001, 0.005, 0.010, 0.015], n_total, 10, 0.3)\n",
    "ox_range = generate_subsequences_of_random_length([0.001, 0.005, 0.010, 0.015], n_total, 15, 0.2)\n",
    "\n",
    "df_prod_sced = pd.DataFrame({\"heat_sq\": np.repeat(range(1, n_total//n_seq + 2), n_seq)[:n_total], \n",
    "                             \"head_id\": [f\"heat-{i}\" for i in range(n_total)],\n",
    "                             \"steel_grade\": grade,\n",
    "                             \"required_weight\": np.random.binomial(160, 0.9, size=n_total),\n",
    "                             \"chemistry\": [{\"cu_pct\": cu_range[i], \"al_pct\": al_range[i], \"ox_pct\": ox_range[i],} for i in range(n_total)]\n",
    "                            })\n",
    "df_prod_sced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data_frame_as_json(df_prod_sced, 'production_schedule_nb.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_total = 100\n",
    "scrap_types = [\"bushling\", \"pig_iron\", \"hbi\"]\n",
    "date_range = pd.date_range(start='1/1/2019', end='03/01/2019').strftime(\"%Y%m%d\")\n",
    "delivery_type = [\"cart\"] * 20 + [\"truck\"] * 3 + [\"ship\"]\n",
    "\n",
    "\n",
    "df_inventory = pd.DataFrame({\"scrap_type\": [choice(scrap_types) for _ in range(n_total)], \n",
    "                             \"delivery_date\": [choice(date_range) for _ in range(n_total)],\n",
    "                             \"delivery_type\": [choice(delivery_type) for _ in range(n_total)],\n",
    "                            }).sort_values(by=\"delivery_date\")\n",
    "\n",
    "def sample_weight(dt):  \n",
    "    if dt == \"cart\":\n",
    "        return np.random.binomial(20, 0.7, size=1)[0]\n",
    "    if dt == \"truck\":\n",
    "        return np.random.binomial(40, 0.9, size=1)[0]\n",
    "    if dt == \"ship\":\n",
    "        return np.random.binomial(3000, 0.5, size=1)[0]\n",
    "    \n",
    "def sample_provider(dt):  \n",
    "    if dt == \"cart\":\n",
    "        return choice(\"aabcdee\")\n",
    "    if dt == \"truck\":\n",
    "        return choice(\"aaaaaccceeee\")\n",
    "    if dt == \"ship\":\n",
    "        return choice(\"bbbbbddd\")\n",
    "    \n",
    "df_inventory[\"sample_weight\"] = df_inventory[\"delivery_type\"].apply(sample_weight)\n",
    "df_inventory[\"provider\"] = df_inventory[\"delivery_type\"].apply(sample_provider)\n",
    "\n",
    "df_inventory.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data_frame_as_json(df_inventory, 'srap_inventory_nb.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = 30\n",
    "\n",
    "df_order = pd.DataFrame({\"scrap_type\": [choice(scrap_types) for _ in range(n_total)],\n",
    "                         \"order_date\": [choice(date_range) for _ in range(n_total)], \n",
    "                         \"status\": \"delivered\", \n",
    "                         \"weight\": np.random.binomial(10000, 0.7, size=n_total), \n",
    "                        }).sort_values(by=\"order_date\")\n",
    "\n",
    "def sample_price(st):   \n",
    "    if st == \"bushling\":\n",
    "        return np.random.binomial(250, 0.7, size=1)[0]\n",
    "    if st == \"pig_iron\":\n",
    "        return np.random.binomial(300, 0.9, size=1)[0]\n",
    "    if st == \"hbi\":\n",
    "        return np.random.binomial(600, 0.5, size=1)[0]\n",
    "    \n",
    "df_order[\"price_per_ton\"] = df_order[\"scrap_type\"].apply(sample_price)\n",
    "df_order[-10:][\"status\"] = \"outstanding\"\n",
    "df_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_data_frame_as_json(df_order, 'srap_orders_nb.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
